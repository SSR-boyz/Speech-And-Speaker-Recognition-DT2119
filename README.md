# Speech-And-Speaker-Recognition-DT2119

### Lab 1 - Feature extraction
- [ ] Compute MFCC features step-by-step.
- [ ] Examine features.
- [ ] Evaluate correlation between feature.
- [ ] Compare utterances with Dynamic Time Warping.
- [ ] Illustrate the discriminative power of the features with respect to words.
- [ ] Perform hierarchical clustering of utterances.
- [ ] Train and analyze a Gaussian Mixture Model of the feature vectors.


### Lab 2 - Hidden Markov Models with Gaussian Emissions
- [ ] Combine phonetic HMMs into word HMMs using a lexicon 
- [ ] Implement the forward-backward algorithm, 
- [ ] Use it compute the log likelihood of spoken utterances given a Gaussian HMM 
- [ ] Perform isolated word recognition 
- [ ] Implement the Viterbi algorithm, and use it to compute Viterbi path and likelihood 
- [ ] Compare and comment Viterbi and Forward likelihoods 
- [ ] ImplementtheBaum-Welch algorithm toupdatetheparametersoftheemissionprobability distributions

### Lab 3 - Phoneme Recognition with Deep Neural Network
- [ ] Using predeﬁned Gaussian-emission HMM phonetic models, create time aligned phonetic transcriptions of the TIDIGITS database, 
- [ ] Deﬁne appropriate DNN models for phoneme recognition using Keras, 
- [ ] Train and evaluate the DNN models on a frame-by-frame recognition score, 
- [ ] Repeat the training by varying model parameters and input features Optional: 
- [ ] Perform and evaluate continuous speech recognition at the phoneme and word level using Gaussian-emission HMM models 
- [ ] Perform and evaluate continuous speech recognition at the phoneme and word level using DNN-HMM models 
